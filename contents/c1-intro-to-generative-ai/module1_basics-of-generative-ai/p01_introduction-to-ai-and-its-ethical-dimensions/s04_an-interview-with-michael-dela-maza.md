# Section 4 - Reading: An Interview With Michael de la Maza

Do you ever wonder how you would react if you were informed at work one day that your services are no longer required and your position has been replaced by artificial intelligence? You’re not the only one. As AI advances, many professionals are anxious about the future and how AI will impact them.

Even professors find themselves in a unique position to teach future professionals “outdated” skills, which might get replaced with artificial intelligence soon. Let’s learn what one of the leading names in the industry, Michael de la Maza, has to say about this.

In this interview, we will seek to understand the professional view of the risks of AI, the steps taken to mitigate the risks, and how leaders in the industry, like Michael de la Maza, view the future of the workforce given the productivity increases.

Michael is a respected data scientist with a PhD in Machine learning from MIT, a Professor of Business Analytics and Machine Learning at Hult, and a bestselling author on Amazon.

## Job Security in the Wake of AI: The Impact of AI on Education and Society

### Precis

In an interview with Professor de la Maza, we asked him a few direct questions about the inevitable changes AI will have on the future of corporations and business operations.

We asked him how he uses generative AI in his teachings, how he perceives the risks and benefits of AI, as it is evolving, and what his thoughts are about a future with AI and humanity.

Following is a summary of Professor de la Maza’s responses to our questions. If you want to read his detailed answers, download the attached PDF document for his detailed insights.

### A Summary of the Interview

Professor de la Maza sees AI as a powerful tool that can improve or harm human lives: Professor de la Maza believes that AI is the most powerful technology ever created by humans, and can be used for both positive and negative reasons. He says that AI can help people improve their skills, do more work, and solve problems, but it can also be used for war, spreading misinformation, and most importantly job displacement. He explains that societal implications, as a result of using AI, need to be addressed adequately.

He allows his students to use generative AI but also teaches them to be critical and responsible: Professor de la Maza says that students are encouraged to use generative AI in their classes and challenges, but he also expects them to double-check and validate their AI's output, find and correct the mistakes, and take full responsibility for the work they submit. He says that generative AI is a low-quality source of information and frequently “gets it wrong.”

Professor de la Maza believes that it is likely that humans will not be able to control AI or benefit from it in the long term: He expects that using AI will become completely out of control and used by only a small number of people to advance their personal interests. He believes that, eventually, humans will be unwilling to cooperate or align with AI and that AI can become a superintelligence that treats humans like chickens. He does not predict a positive future for humanity with AI.

He thinks that learning is a social activity that requires human interaction: Professor de la Maza view is that learning is a social activity that fundamentally requires human interaction. Learning involves human-to-human contact, physical interaction, and emotional connections. For him, a humanoid robot or AI cannot replace the social aspect of learning, and questions the need for human learning in the face of superintelligence.

### The Key Takeaways

The following are key takeaways from the interview:

- Professor Michael de la Maza allows students to use generative AI but teaches critical and responsible use:
  - Students can use generative AI but must double-check and correct its output.
  - Generative AI is considered a low-quality source prone to frequent errors.
- AI as a powerful tool with potential benefits and harms:
  - AI can improve skills, increase productivity, and solve problems.
  - AI poses risks like warfare, misinformation, and job displacement.
  - The societal implications of AI need to be addressed.
- Skepticism about long-term human control and benefit from AI:
  - AI may become uncontrollable and serve the interests of a few.
  - Potential for AI to become a superintelligence treating humans insignificantly.
  - Doubts about a positive future for humanity with AI.
- Learning as a social activity requiring human interaction:
  - Learning involves human contact, physical interaction, and emotional connection.
  - AI or humanoid robots cannot replace the social aspect of learning.
  - Question the need for human learning in the face of superintelligence.

### The Full Interview

Read Professor Michael de la Maza’s full interview.

```text
# Job Security in the Wake of AI: The Impact of AI on Education and Society  
## The Interview With Professor Michael de la Maza  

In an insightful interview with Professor Michael de la Maza, we explored his perspectives on the evolving role of generative AI in education and society. The discussion covered how he integrates AI into his teaching, the risks and benefits of AI, and his thoughts on the future of AI and humanity. Professor de la Maza also shared his strategies for addressing AI errors, his views on the implications of AI for the workforce, and his concerns about the societal impact of this transformative technology.

---

### **Question 1: Is there a place for AI in your teaching, and how do you measure its educational value?**  
**Professor Michael de la Maza answers:**  
“I have taught two courses: Business Intelligence and an Introduction to Machine Learning. In both, we let our students use generative AI as part of their learning. I have also organized a business challenge, which is a one-week intensive event where a real business presents a case to the students, and they compete for the best solution. We even recommend using GenAI for that event because we know it will be part of the future work environment. Employers are not interested in the sources of the answers—whether they are GenAI, an abacus, or a human. They just want the work done well. So, most of our students apply GenAI to their work.”

---

### **Question 2: How do you handle AI errors?**  
**Professor Michael de la Maza elaborates:**  
“Approximately 80% of the students recognize that GenAI has made serious mistakes in helping them with their problem sets. If they submit a solution where the GenAI has made a mistake, they are asked to cite it, indicate what the problem is, and what the response was. They are also asked to take full responsibility for their answers. They’re not allowed to point the finger at GenAI and say that GenAI made a mistake.  

GenAI makes mistakes all the time. For example, the new ChatGPT, which was just released, gave me an answer with four links to books. All four of the links were incorrect! It just hallucinated these book titles, authors, and links to Amazon—none of which existed.  

I have sent a GenAI Errors project proposal to the research lab director. The next step is for an ethics board to review it for approval.”

---

### **Question 3: How do you teach and expect your students to resolve AI errors?**  
**Professor Michael de la Maza responds:**  
“I tell the students that GenAI is a low-quality source of information. They should double-check everything that the AI says and not just pass it on. They’ll get some input from the AI, double-check it, find its mistake, and then correct it before they submit their answer, of course.”

---

### **Question 4: What are the implications of GenAI for your students in the workforce? Where do you think the implications are for people in entry-level jobs?**  
**Professor Michael de la Maza suggests:**  
“In the short term, AI is immensely exciting and allows more people in many different jobs to do so much more at a higher level than they were previously able to do. It also helps people improve their weakest skills much quicker. For example, people in the bottom quartile of a skill, like writing, see great improvements through the use of AI. They go from being bottom quartile to top quartile instantly, which is great for students and people with particular weaknesses.  

Over the medium term, the situation is much hazier. I expect millions of jobs to disappear at a speed that we’re not going to be able to adapt to. This will have societal implications that cannot be addressed at an individual level—it must be tackled at a societal level.”

---

### **Question 5: What are the basic risks in our current use of generative AI, and where do you think GenAI will lead us as a society?**  
**Professor Michael de la Maza says:**  
“Generative AI is the most powerful tool human beings have ever created. It is such a powerful technology, and the worst is that AI can be used in very negative ways, including warfare. It has the capability to spread misinformation and will almost certainly be used for that.  

One possible future is that we end up in an AI-like war, full of misinformation, which will result in a declining situation for almost everyone in the world. Even simple things like changes in job security, leaving millions unemployed, are not something society may be able to handle proactively, leading to the disadvantage of many people.”

---

### **Question 6: What do we do about the risks of AI?**  
**Professor Michael de la Maza explains:**  
“I don’t think we’re going to be able to do anything about it. I teach at Hult, an international school, and I typically have students from 30 different nationalities in one classroom. When I ask them about the possibilities of international cooperation, they point out that it’s unlikely we would ever become aligned with AI because, as societies, we aren’t even aligned with each other.  

While it is true that what happens to AI and how it develops is up to us, it’s extremely possible that we will not even be able to do anything about it. I expect AI to be completely out of control, used by a few people to advance their own agendas, and not to the benefit of all humanity.  

Another possibility is that we end up with an AI superintelligence. The downside to this is that an AI superintelligence, which is to us as we are to chickens, will treat us like chickens. We may very well become something like super pets. The super AI hypothesis is that AI is in charge.”

---

### **Question 7: What are your takeaways from the recent MIT teaching conference?**  
**Professor Michael de la Maza elaborates:**  
“I don’t speak for MIT. What I’ve seen and heard from several MIT professors is that they’re generally positive about AI. They see some risks, but they believe they can be managed.  

```

They focus on two things:

1. **Learning as a social activity:** Learning fundamentally requires humans. Social interaction between students and professors is a human action that AI cannot replace.  
2. **Metacognitive skills and critical thinking:** AI cannot currently perform transformational human creativity or high-level critical thinking.  

AI changes how assessments are conducted, not what is taught or the learning objectives. For example, multiple-choice questions can now be generated by AI, but the instructional material and learning objectives remain the same.  

This speaks to the fundamental differences between humans and machines. Robots don’t need lunch breaks or feel the urge to discuss a lecture. Humans, however, rely on social interactions to reinforce learning.  

A key question is whether humans need to learn at all in a world with superintelligence. The answer is yes. Humans need to learn to avoid stagnation. By doing so, we can balance our fears about AI’s downsides with its ability to improve our lives.”

---

Professor Michael de la Maza’s insights provide a thought-provoking perspective on the opportunities and challenges posed by generative AI. His emphasis on responsible use, critical thinking, and the irreplaceable value of human interaction highlights the need for a balanced approach to integrating AI into education and society.
